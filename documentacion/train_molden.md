# An√°lisis Detallado del Script de Entrenamiento MLB

## üìã √çndice
1. [Visi√≥n General](#visi√≥n-general)
2. [Arquitectura del Sistema](#arquitectura-del-sistema)
3. [Funciones de Scraping](#funciones-de-scraping)
4. [Extracci√≥n de Features](#extracci√≥n-de-features)
5. [Pipeline de Entrenamiento](#pipeline-de-entrenamiento)
6. [Por Qu√© 37 Features](#por-qu√©-37-features)

---

## üéØ Visi√≥n General

### Objetivo del Script
Este script entrena un modelo de Machine Learning para predecir el ganador de partidos de b√©isbol MLB (local vs visitante) bas√°ndose en:
- Estad√≠sticas hist√≥ricas de equipos
- Rendimiento de lanzadores iniciales
- Caracter√≠sticas de los mejores bateadores

### Filosof√≠a de Dise√±o
El script sigue un enfoque de **enriquecimiento de datos**: toma datos b√°sicos (equipos, lanzadores, resultado) y los enriquece con estad√≠sticas detalladas mediante web scraping de Baseball Reference.

---

## üèóÔ∏è Arquitectura del Sistema

### Estructura del Flujo de Datos

```
CSV Hist√≥rico ‚Üí Scraping Web ‚Üí Feature Engineering ‚Üí Modelo ML ‚Üí Predicciones
    ‚Üì              ‚Üì                 ‚Üì                  ‚Üì
Partidos      Stats de        37 Features       RandomForest/
B√°sicos       Baseball-Ref    Calculadas        GradientBoosting
```

### Componentes Principales

1. **M√≥dulo de Scraping**: Extrae estad√≠sticas actualizadas
2. **Feature Extractor**: Transforma stats en features predictivas
3. **Pipeline ML**: Entrena y eval√∫a m√∫ltiples modelos
4. **Sistema de Cache**: Optimiza tiempos de re-entrenamiento

---

## üï∑Ô∏è Funciones de Scraping

### 1. `obtener_html(url)`

**Prop√≥sito**: Obtener HTML de forma robusta evitando bloqueos

```python
def obtener_html(url):
    scraper = cloudscraper.create_scraper()
```

**Por qu√© cloudscraper**:
- Baseball Reference usa protecci√≥n Cloudflare
- `requests` normal ser√≠a bloqueado
- cloudscraper simula un navegador real

**Manejo de errores**:
- Timeout de 15 segundos (evita colgarse)
- Verifica status code 200
- Retorna `None` si falla (permite continuar)

---

### 2. `limpiar_dataframe(df)`

**Prop√≥sito**: Sanitizar tablas HTML parseadas

**Problemas que resuelve**:

1. **Filas de totales**: "Team Totals" no son jugadores
2. **Filas de ranking**: "Rank in 14th" contamina datos
3. **Filas vac√≠as**: Espaciadores HTML
4. **Columna Rk**: No aporta informaci√≥n (es solo n√∫mero de fila)

**Por qu√© es cr√≠tico**:
Sin esta limpieza, el modelo intentar√≠a "aprender" de filas que no son jugadores reales.

---

### 3. `scrape_player_stats(team_code, year)`

**Prop√≥sito**: Extraer estad√≠sticas completas de un equipo

**Estrategia**:
```python
url = f"https://www.baseball-reference.com/teams/{team_code}/{year}.shtml"
```

**Dos tablas clave**:
- `players_standard_batting`: Estad√≠sticas ofensivas
- `players_standard_pitching`: Estad√≠sticas de pitcheo

**Por qu√© ambas**:
- Necesitamos contexto completo del equipo
- Un equipo fuerte ofensivamente + pitcheo d√©bil ‚â† victoria garantizada
- El b√©isbol es balance entre ataque y defensa

**Manejo robusto**:
```python
if batting_table:
    try:
        batting_df = pd.read_html(str(batting_table))[0]
```
- Contin√∫a aunque falle una tabla
- Retorna `None, None` si todo falla
- Permite al c√≥digo principal decidir qu√© hacer

---

### 4. `safe_float(val)`

**Prop√≥sito**: Convertir valores de forma defensiva

**Por qu√© existe**:
- HTML puede tener: "3.45", "‚Äî", "", "N/A"
- `float("‚Äî")` crashear√≠a el programa
- Retornar 0.0 es mejor que crashear (el modelo aprender√° que 0 = sin dato)

---

### 5. `encontrar_lanzador(pitching_df, nombre_lanzador)`

**Prop√≥sito**: Buscar lanzador espec√≠fico y extraer sus estad√≠sticas clave

**Estad√≠sticas extra√≠das**:
- **ERA** (Earned Run Average): Carreras limpias por 9 innings
- **WHIP** (Walks + Hits per Inning): Corredores permitidos por inning
- **H9**: Hits permitidos por 9 innings
- **W/L**: Record de victorias/derrotas
- **IP**: Innings lanzados (indica experiencia)

**Por qu√© estas m√©tricas**:
- **ERA**: El mejor predictor de efectividad de un lanzador
  - ERA < 3.00 = Excelente
  - ERA > 5.00 = Problema
- **WHIP**: Captura presi√≥n sobre el lanzador
  - WHIP < 1.00 = Elite
  - WHIP > 1.50 = Vulnerable
- **H9**: Complementa WHIP (aislando hits)

**B√∫squeda flexible**:
```python
mask = pitching_df[name_col].astype(str).str.lower().str.contains(nombre_busqueda, na=False)
```
- Permite "Cole" encontrar "Gerrit Cole"
- Case-insensitive
- Maneja variaciones de nombres

**Fallback a None**:
Si no encuentra al lanzador, retorna `None` ‚Üí el extractor pondr√° 0s ‚Üí el modelo aprende "sin informaci√≥n de lanzador"

---

### 6. `encontrar_mejor_bateador(batting_df)`

**Prop√≥sito**: Identificar poder ofensivo del equipo

**Estrategia innovadora**:
```python
mediana_ab = batting_df['AB'].median()
batting_filtrado = batting_df[batting_df['AB'] > mediana_ab]
```

**Por qu√© filtrar por AB (At Bats)**:
- Evita "outliers" de jugadores con pocos turnos
- Un jugador con BA=1.000 en 2 AB no representa al equipo
- Mediana asegura considerar solo titulares regulares

**Top 3 promediados**:
```python
top_3 = batting_filtrado.sort_values('OBP', ascending=False).head(3)
```

**Por qu√© promediar top 3 y no tomar solo #1**:
- El b√©isbol es un deporte de equipo
- Un s√∫per estrella + 8 malos ‚â† victoria
- Top 3 captura "n√∫cleo ofensivo"

**Estad√≠sticas elegidas**:
- **BA** (Batting Average): Hits / At Bats
- **OBP** (On-Base Percentage): Incluye bases por bolas
- **RBI** (Runs Batted In): Capacidad de impulsar carreras
- **R** (Runs): Carreras anotadas

**Por qu√© OBP > BA para ordenar**:
- OBP es mejor predictor de carreras que BA
- "Tres cosas ciertas: muerte, impuestos, y el OBP predice mejor" - Bill James

---

### 7. `calcular_stats_equipo(batting_df, pitching_df)`

**Prop√≥sito**: Obtener contexto agregado del equipo completo

**Por qu√© promedios del equipo adem√°s de mejores jugadores**:
- Captura **profundidad** del roster
- Un equipo con 9 jugadores s√≥lidos > equipo con 3 estrellas
- En b√©isbol, todos batean ‚Üí profundidad importa

---

## üîß Extracci√≥n de Features

### `extraer_features_partido(row, verbose=False)`

Esta es la **funci√≥n m√°s importante** del script. Transforma un partido simple en un vector de 37 features.

### Proceso paso a paso:

#### 1. **Obtener datos de ambos equipos**
```python
batting1, pitching1 = scrape_player_stats(row['home_team'], row['year'])
batting2, pitching2 = scrape_player_stats(row['away_team'], row['year'])
```

#### 2. **Calcular estad√≠sticas agregadas**
```python
stats_team1 = calcular_stats_equipo(batting1, pitching1)
stats_team2 = calcular_stats_equipo(batting2, pitching2)
```

Genera features tipo:
- `home_team_BA_mean`
- `home_team_OBP_mean`
- `home_team_ERA_mean`
- etc.

#### 3. **Extraer stats de lanzadores espec√≠ficos**
```python
pitcher1_stats = encontrar_lanzador(pitching1, row['home_pitcher'])
```

Genera features tipo:
- `home_pitcher_ERA`
- `home_pitcher_WHIP`
- `home_pitcher_H9`
- `home_pitcher_W`
- `home_pitcher_L`

#### 4. **Extraer stats de mejores bateadores**
```python
best_batter1 = encontrar_mejor_bateador(batting1)
```

Genera features tipo:
- `home_best_BA`
- `home_best_OBP`
- `home_best_RBI`
- `home_best_R`

#### 5. **Calcular features derivadas (CR√çTICO)**
```python
features['pitcher_ERA_diff'] = features['away_pitcher_ERA'] - features['home_pitcher_ERA']
```

**Por qu√© diferencias**:
- El modelo ML aprende mejor de **comparaciones** que valores absolutos
- ERA=3.0 vs ERA=4.0 ‚Üí diff=-1.0 (ventaja local)
- Simplifica el aprendizaje: diff > 0 = ventaja local

**Features derivadas calculadas**:
1. `pitcher_ERA_diff`: ¬øQui√©n tiene mejor lanzador?
2. `pitcher_WHIP_diff`: ¬øQui√©n permite menos corredores?
3. `pitcher_H9_diff`: ¬øQui√©n permite menos hits?
4. `team_BA_diff`: ¬øQui√©n batea mejor?
5. `team_OBP_diff`: ¬øQui√©n se embasiza m√°s?

---

## üéì Pipeline de Entrenamiento

### `entrenar_modelo()`

### Fase 1: Carga y Validaci√≥n

```python
df = pd.read_csv(csv_path)
print(f"Total de partidos: {len(df)}")
```

**Verifica distribuci√≥n de clases**:
```python
print(f"Victorias locales (1): {(df['ganador'] == 1).sum()}")
```

**Por qu√© importa**:
- Datasets desbalanceados (90% local gana) ‚Üí modelo aprende "siempre predice local"
- B√©isbol real: ~54% local gana ‚Üí dataset debe reflejarlo

---

### Fase 2: Sistema de Cache

```python
if usar_cache:
    with open(cache_path, 'rb') as f:
        cache_data = pickle.load(f)
```

**Por qu√© cache es esencial**:
- Scraping de 3000 partidos = **varias horas**
- Re-entrenar el modelo sin cache = repetir scraping
- Cache permite iterar en hyperpar√°metros sin re-scrapear

**Qu√© se cachea**:
- `X`: DataFrame de features (37 columnas √ó N partidos)
- `y`: Array de labels (ganador: 0 o 1)

---

### Fase 3: Extracci√≥n de Features

```python
for idx, row in df.iterrows():
    features = extraer_features_partido(row, verbose=False)
    if features:
        features_list.append(features)
        labels.append(row['ganador'])
    time.sleep(1.5)  # Ser amigable con el servidor
```

**Por qu√© `time.sleep(1.5)`**:
- Baseball Reference bloquear√° IPs con > 20 requests/minuto
- 1.5 segundos = ~40 requests/minuto = seguro
- Sin esto: IP baneada a mitad del scraping

**Manejo de fallos**:
```python
if features:
    features_list.append(features)
else:
    partidos_fallidos += 1
```
- No crashea por un partido fallido
- Contin√∫a con los dem√°s
- Reporta cu√°ntos fallaron

---

### Fase 4: Preparaci√≥n de Datos

#### Split Train/Test
```python
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)
```

**Por qu√© `stratify=y`**:
- Asegura misma proporci√≥n local/visitante en train y test
- Sin stratify: test podr√≠a ser todo locales ‚Üí m√©tricas enga√±osas

**80/20 split**:
- 80% entrena el modelo
- 20% eval√∫a desempe√±o real
- Est√°ndar en ML para datasets medianos

#### Escalado de Features
```python
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
```

**Por qu√© escalar**:
- ERA t√≠pico: 3-5
- RBI t√≠pico: 50-120
- Sin escalar: modelo priorizar√≠a RBI (n√∫meros m√°s grandes)
- StandardScaler: transforma a media=0, std=1
- Ahora ERA y RBI tienen misma "importancia num√©rica"

**Fit solo en train**:
```python
scaler.fit_transform(X_train)  # Calcula media/std
X_test_scaled = scaler.transform(X_test)  # Usa misma media/std
```
- Previene "data leakage"
- Test no debe influir en transformaciones

---

### Fase 5: Entrenamiento de M√∫ltiples Modelos

```python
modelos = {
    'Random Forest': RandomForestClassifier(...),
    'Gradient Boosting': GradientBoostingClassifier(...),
    'Logistic Regression': LogisticRegression(...)
}
```

**Por qu√© 3 modelos**:
No sabemos a priori cu√°l funcionar√° mejor con estos datos espec√≠ficos.

#### Random Forest
```python
RandomForestClassifier(
    n_estimators=200,    # 200 √°rboles de decisi√≥n
    max_depth=15,        # Profundidad m√°xima por √°rbol
    min_samples_split=5, # Min muestras para dividir nodo
    random_state=42,     # Reproducibilidad
    n_jobs=-1            # Usar todos los cores CPU
)
```

**Ventajas**:
- Robusto a overfitting
- Maneja features no lineales
- Provee feature importance

**Cu√°ndo funciona bien**:
- Datos con interacciones complejas
- "ERA bajo + BA alto = victoria m√°s probable"

#### Gradient Boosting
```python
GradientBoostingClassifier(
    n_estimators=150,
    max_depth=5,
    learning_rate=0.1
)
```

**Diferencia con RF**:
- RF: √°rboles independientes
- GB: cada √°rbol corrige errores del anterior
- T√≠picamente m√°s preciso pero m√°s lento

#### Logistic Regression
```python
LogisticRegression(max_iter=1000)
```

**Por qu√© incluirlo**:
- Es el "baseline" simple
- Si RF/GB apenas lo superan ‚Üí se√±al de que datos son simples
- √ötil para interpretabilidad

---

### Fase 6: Evaluaci√≥n

#### M√©tricas calculadas:

1. **Accuracy**: % de predicciones correctas
   - F√°cil de entender
   - Problema: no distingue tipo de error

2. **ROC-AUC**: √Årea bajo curva ROC
   - 0.5 = azar
   - 1.0 = perfecto
   - Mejor que accuracy para clases desbalanceadas

3. **Cross-Validation (5-fold)**:
```python
cv_scores = cross_val_score(modelo, X_train_scaled, y_train, cv=5)
```

**Por qu√© CV**:
- Train/test split es **una** partici√≥n aleatoria
- CV hace 5 splits diferentes
- Promedio de 5 ‚Üí estimaci√≥n m√°s robusta
- Desviaci√≥n est√°ndar ‚Üí qu√© tan estable es el modelo

---

### Fase 7: Selecci√≥n del Mejor Modelo

```python
mejor_modelo_nombre = max(resultados.items(), key=lambda x: x[1]['accuracy'])[0]
```

**Criterio**: Accuracy m√°xima en test set

**Por qu√© accuracy aqu√≠**:
- Clases balanceadas en b√©isbol (~54% local)
- F√°cil de comunicar: "acierta 63% de partidos"

---

### Fase 8: An√°lisis del Mejor Modelo

#### Classification Report
```
              precision    recall  f1-score
Away Win         0.60      0.55      0.57
Home Win         0.65      0.70      0.67
```

**Interpretaci√≥n**:
- **Precision**: De los que predijo local, % que fueron local
- **Recall**: De los locales reales, % que predijo
- **F1**: Balance entre precision y recall

#### Confusion Matrix
```
                 Predicted
                 Away  Home
   Actual Away    110    90
   Actual Home     80   120
```

**Lectura**:
- Diagonal = aciertos
- Off-diagonal = errores
- Muestra **tipo** de errores (falsos positivos vs negativos)

#### Feature Importance
```python
if hasattr(mejor_modelo, 'feature_importances_'):
```

**Solo RF/GB tienen esto**:
- Muestra qu√© features m√°s influyeron
- T√≠picamente: ERA, WHIP, OBP ser√°n top

**Utilidad**:
- Validaci√≥n: ¬øel modelo usa features sensatas?
- Simplificaci√≥n: ¬øpodemos quitar features poco importantes?

---

### Fase 9: Persistencia

```python
pickle.dump(mejor_modelo, f)      # Modelo entrenado
pickle.dump(scaler, f)            # Escalador (crucial!)
pickle.dump(list(X.columns), f)   # Nombres de features
```

**Por qu√© 3 archivos**:
1. **Modelo**: Pesos aprendidos
2. **Scaler**: Para transformar datos nuevos igual que train
3. **Feature names**: Para asegurar orden correcto de features

**Sin scaler**:
```python
# Entrenamiento: ERA escalado a -1.5
# Predicci√≥n: ERA sin escalar = 3.5
# Modelo: "Este 3.5 es alt√≠simo!" (asume escala de train)
# Resultado: Predicci√≥n err√≥nea
```

---

## üìä Por Qu√© 37 Features

### Desglose Completo:

#### Features de Equipo (14 features)

**Local (7)**:
1. `home_team_BA_mean` - Promedio de bateo del equipo
2. `home_team_OBP_mean` - Promedio de embase del equipo
3. `home_team_RBI_mean` - Promedio de carreras impulsadas
4. `home_team_R_mean` - Promedio de carreras anotadas
5. `home_team_ERA_mean` - ERA promedio del pitcheo
6. `home_team_WHIP_mean` - WHIP promedio del pitcheo
7. `home_team_H9_mean` - H9 promedio del pitcheo

**Visitante (7)**:
8-14. Mismas stats para equipo visitante con prefijo `away_`

**Por qu√© estas**:
- Capturan **calidad general** del roster
- BA/OBP/RBI/R ‚Üí poder ofensivo
- ERA/WHIP/H9 ‚Üí calidad de pitcheo

---

#### Features de Lanzador Inicial (10 features)

**Local (5)**:
15. `home_pitcher_ERA`
16. `home_pitcher_WHIP`
17. `home_pitcher_H9`
18. `home_pitcher_W` - Victorias
19. `home_pitcher_L` - Derrotas

**Visitante (5)**:
20-24. Mismas stats para lanzador visitante

**Por qu√© estas**:
- Lanzador inicial determina primeros 5-7 innings
- W/L captura "clutch" y soporte del equipo
- ERA/WHIP/H9 ‚Üí efectividad pura

---

#### Features de Mejores Bateadores (8 features)

**Local (4)**:
25. `home_best_BA` - BA promedio top 3
26. `home_best_OBP` - OBP promedio top 3
27. `home_best_RBI` - RBI promedio top 3
28. `home_best_R` - R promedio top 3

**Visitante (4)**:
29-32. Mismas stats para top 3 visitantes

**Por qu√© estas**:
- Estrellas ganan partidos
- Top 3 captura n√∫cleo ofensivo sin outliers
- Complementa promedios de equipo (elite vs profundidad)

---

#### Features Derivadas (5 features)

33. `pitcher_ERA_diff` = away_ERA - home_ERA
34. `pitcher_WHIP_diff` = away_WHIP - home_WHIP
35. `pitcher_H9_diff` = away_H9 - home_H9
36. `team_BA_diff` = home_BA - away_BA
37. `team_OBP_diff` = home_OBP - away_OBP

**Por qu√© estas son CR√çTICAS**:
- Facilitan aprendizaje del modelo
- Diff > 0 en pitcher_ERA_diff ‚Üí ventaja local clara
- Modelo no tiene que "descubrir" que debe comparar
- En experimentos: +5-10% accuracy vs sin diffs

---

## üéØ Resumen de Dise√±o

### Principios Clave:

1. **Robustez**: Maneja fallos sin crashear
2. **Eficiencia**: Cache evita re-scraping
3. **Interpretabilidad**: Features tienen significado real de b√©isbol
4. **Balance**: Stats de pitcheo + bateo + equipo + individuales
5. **Comparabilidad**: Features derivadas facilitan aprendizaje

### Limitaciones Actuales:

1. **Scraping lento**: 3000 partidos = 2-3 horas
2. **Sin contexto temporal**: No considera racha reciente
3. **Sin venue**: No considera estadio (parque peque√±o vs grande)
4. **Sin clima**: Viento/temperatura afectan fly balls
5. **Sin lineup**: Asume mismos jugadores siempre

### Por Qu√© Funciona:

El modelo combina:
- **Nivel macro**: Calidad del equipo completo
- **Nivel meso**: Efectividad del lanzador inicial
- **Nivel micro**: Estrellas ofensivas

Esta jerarqu√≠a de informaci√≥n replica c√≥mo analistas humanos eval√∫an partidos.

---

## üìà Pr√≥ximos Pasos Sugeridos

1. **Features temporales**: √öltimos 10 partidos
2. **Features de contexto**: Estadio, divisi√≥n
3. **Optimizaci√≥n**: Paralelizar scraping
4. **Validaci√≥n temporal**: Train en 2022, test en 2023
5. **Ensemble**: Combinar m√∫ltiples modelos